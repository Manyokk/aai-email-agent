# Project Title: [Name of Your AI Agent]

**Course:** Agentic Artificial Intelligence
**Team Name:** [Your Team Name]

## Team Members

- Hendrik Scholz (TheRex1305)
- Sezer Ege Dikmen (Manyokk)
- Arsham Kuhnavardasli (Rshvm)

---

## 1. Executive Summary

_(**Purpose:** To provide a high-level, managerial overview. Motivate your solution.)_

_(Write a concise summary (approx. 250-400 words) for a non-technical stakeholder. Answer the following:_

- _What specific problem or business need does your agent address?_
- _What is your solution? Describe the agent's main function in one or two sentences on an abstract level._
- _What is the key capability or "magic" of your system? (e.g., "It autonomously analyzes customer support tickets and routes them to the correct department with a summarized solution.")_
- _What is the potential value or impact of this agent? (e.g., "This system can reduce manual sorting time by 90%...")_

---

## 2. Introduction & Problem Statement

_(**Purpose:** To define the context and goals of your project.)_

- **Problem:** Describe the problem you are solving in detail. Who faces this problem? Why is it difficult? What are the limitations of existing solutions? Why does an agentic AI approach hold potential to solve this problem compared to other (non-agentic) approaches (it is key to address this question).
- **Objectives:** What are the specific, measurable goals of your agent? (e.g., "The agent must successfully achieve 8/10 tasks," or "The agent must be able to book a meeting by finding a common free slot in two calendars.")
- **Scope:** What _does_ your agent do, and just as importantly, what _doesn't_ it do? Define the boundaries of your project.

---

## 3. System Architecture

_(**Purpose:** To explain the high-level design of your agent.)_

_(Provide a high-level diagram of your agent's architecture. You can create this in a tool like draw.io, export it as a .png or .jpg, and embed it here.)_

`![Architecture Diagram](path/to/your/diagram.png)`

_(Explain the diagram and the overall workflow:_

- _What are the main components? (e.g., Graph, Nodes and Edges, Core Logic, Tool/API Layer, Memory)._
- _How does data flow through the system? Start with a user input and trace its path._
- _If using **LangGraph**, this is the most important place to describe your graph. What are the nodes (e.g., `call_model`, `execute_tools`)? What are the edges (especially conditional edges)? What is the structure of your `State` object?)_

---

## 4. Implementation Details

_(**Purpose:** To detail the "how" of your project, covering the specific technical choices.)_

### 4.1. LLM Selection & Configuration

- **Models Used:** Which LLM(s) did you use? (e.g., `Gemini 2.5 Flash`, `Ollama/llama3:8b`).
- **Justification:** _Why_ did you choose these models? Discuss your reasoning based on:
  - Performance (quality of responses for your task)
  - Speed (latency)
  - Cost (API costs vs. free local models)
  - Context Window size
  - Accessibility (e.g., "We used Ollama for local development to avoid API costs and Gemini for the final deployment due to its superior reasoning.")
- **Hyperparameters:** What settings did you use (e.g., `temperature`, `top_p`, `max_tokens`)? Explain your choices.
  - _(e.g., "We set `temperature=0.1` for tasks requiring factual tool use and `temperature=0.7` for the final answer-generation step to make it sound more natural.")_

### 4.2. Key Components (Memory, Tools)

- **Tools:** List and describe each tool (also MCPs) you defined for your agent.
  - _(e.g., `get_weather(city: str) -> str`: Fetches the current weather. `search_database(query: str) -> List[dict]`: Queries our product database.)_
- **Memory:** What kind of memory does your agent have?
  - _(e.g., "We used `ConversationBufferWindowMemory` from LangChain with k=5. This allows the agent to 'remember' the last 5 user/AI interactions, providing context for follow-up questions without overloading the context window.")_
  - _(Or, "We implemented a simple RAG (Retrieval-Augmented Generation) system. We used a Chroma vector store to hold product manuals, and the agent has a tool to query this store.")_

### 4.3. Prompt Engineering

_(This is a critical section. Show your work.)_

- **System Prompt:** Include your final system prompt here. Explain the different parts of the prompt and why you included them (e.g., setting the persona, rules, tool instructions).
- **Prompting Techniques:** Explain how you used concepts from the lecture in your prompts or agent design.
  - **Chain of Thought (CoT):** Did you instruct the agent to "think step-by-step"? Show where. How did this improve performance?
  - **ReAct (Reasoning and Acting):** If you built a ReAct-style agent, explain how the model is prompted to produce a `Thought:` and an `Action:` (or the JSON equivalent).
  - **Tree of Thought (ToT):** Did you implement anything like this? (e.g., using LangGraph to have one node generate 3 possible plans and another node evaluate and pick the best one).
- **Prompt Evolution:** (Optional but recommended) Briefly describe how your prompt changed. What was your first, simple prompt, and what did you have to add to fix errors or improve behavior?

### 4.4. Context Engineering

_(**Purpose:** To explain how you manage and structure the context that your agent uses to make decisions.)_

- **Context Structure:** How do you organize and structure the context passed to your LLM? What information is included in each context window?
  - _(e.g., "We structure our context as: [System Prompt] + [Conversation History (last 5 turns)] + [Current User Query] + [Tool Results]. We use a fixed template to ensure consistent formatting.")_
- **Context Window Management:** How do you handle context window limits? Do you truncate, summarize, or prioritize certain information?
  - _(e.g., "We use a sliding window approach. When the context approaches the token limit, we summarize older conversation turns using a separate LLM call, keeping only the most recent 3 turns in full detail.")_
  - _(Or, "We prioritize tool results and recent messages. If the context exceeds the limit, we remove the oldest conversation turns first, as they are less relevant to the current task.")_
- **Context Retrieval:** If you use RAG or external knowledge bases, how do you retrieve and rank relevant context?
  - _(e.g., "We use semantic search with cosine similarity to retrieve the top 3 most relevant documents from our vector store. We then include these as context before the current query.")_
- **Context Compression/Summarization:** Do you use any techniques to compress or summarize context to fit more information?
  - _(e.g., "We implemented a two-tier memory system: detailed memory for the last 2 turns, and summarized memory for turns 3-10. This allows us to maintain longer conversation context without exceeding token limits.")_
- **Dynamic Context Selection:** Does your agent dynamically select which context to include based on the task?
  - _(e.g., "For tool-calling tasks, we include detailed tool documentation. For general conversation, we prioritize conversation history. The agent's router node decides which context template to use.")_

---

## 5. Evaluation & Challenges

_(**Purpose:** To critically assess your project. What worked and what didn't?)_

- **Testing & Results:** How did you test your agent? What scenarios did you use?
  - Show 2-3 examples of your agent working **well**. (Include user input and agent output).
  - Show 1-2 examples of your agent **failing** or struggling. Explain _why_ it failed (e.g., "The agent misinterpreted the user's intent," "The tool returned bad data," "The LLM hallucinated").
- **Challenges Faced:** What was the hardest part of this project?
  - _(e.g., "Getting the agent to reliably call the correct tool with the correct JSON format was very difficult." or "Managing the agent's state in LangGraph was complex.")_
- **Limitations:** What are the known limitations of your final agent?

---

## 6. Theoretical Foundations: Agentic Characteristics

_(**Purpose:** To connect your practical implementation to the core theory from the lecture.)_

_(Analyze your agent's design and behavior based on Wooldridge's four characteristics of agentic software as well plus learning capabilities as fifth characteristic. Be honest in your assessment.)_

- **Autonomy:** To what extent does your agent operate without direct human intervention? Does it make its own decisions to achieve its goals? Provide examples.
  - _(e.g., "Our agent exhibits moderate autonomy. It can decide which tool to use (search or database) based on the user query without being told. However, it cannot initiate a new task on its own and requires a user prompt to start.")_
- **Social Ability:** Does your agent interact with other agents or humans (beyond the initial user)? Did you design any communication protocols?
  - _(e.g., "The agent has low social ability. It only communicates with the end-user. We did not implement any agent-to-agent communication.")_
- **Reactiveness:** How does your agent perceive its environment and respond to changes? The "environment" could be new user input, new data from a tool (like a web search), or an error.
  - _(e.g., "The agent is highly reactive. It perceives its environment through tool outputs. If a search tool returns an error, the agent (using its ReAct logic) perceives this state change and attempts to re-run the search with a different query.")_
- **Proactiveness:** Does your agent exhibit goal-directed behavior? Does it take the initiative rather than just reacting?
  - _(e.g., "The agent shows simple proactiveness. Its goal is to answer the user's question. If the initial search result is insufficient, it proactively decides to perform a second, more specific search to gather more information before presenting an answer, rather than just giving a poor answer.")_
- **Continual Learning:** Does your agent learn over time? Can it adapt its behavior based on experience, feedback, or new information? How does it retain and apply learned knowledge?
  - _(e.g., "Our agent does not implement continual learning in the traditional sense. It does not update its model weights or learn from past interactions. However, it uses conversation memory to maintain context within a session, which allows it to adapt its responses based on the current conversation history.")_
  - _(Or, "Our agent implements a form of continual learning through a feedback mechanism. When users provide explicit feedback (thumbs up/down), we store successful tool-call patterns in a knowledge base. The agent can query this knowledge base to learn from past successful interactions and improve its tool selection over time.")_
  - _(Or, "We implemented a simple form of learning through a vector store that accumulates successful query-response pairs. The agent uses semantic search to retrieve similar past interactions and adapts its approach based on what worked before. However, this is limited to in-memory storage and does not persist across sessions.")_

---

## 7. Ethical Considerations

_(**Purpose:** To demonstrate awareness of the ethical implications of deploying AI agents and to discuss how your agent addresses or should address these concerns.)_

_(Discuss the ethical dimensions of your agent. Consider the following aspects and address those that are relevant to your specific agent:)_

- **Bias & Fairness:** Does your agent have the potential to exhibit bias? How might it treat different users or groups differently? What steps did you take (or should be taken) to mitigate bias?
  - _(e.g., "Our agent uses a language model that may have been trained on biased data. We tested our agent with queries from diverse user personas and monitored for discriminatory outputs. We added explicit instructions in our system prompt to treat all users fairly.")_
- **Privacy & Data Security:** What data does your agent collect, store, or process? How is user data handled? What privacy concerns arise from your agent's memory or tool usage?
  - _(e.g., "Our agent stores conversation history in memory. We implemented data encryption and ensured that sensitive information (like personal identifiers) is not logged. Users can request deletion of their conversation history.")_
- **Transparency & Explainability:** Can users understand how your agent makes decisions? Is the agent's reasoning process transparent? What happens when the agent makes a mistake?
  - _(e.g., "Our agent uses a ReAct pattern that outputs its reasoning steps. However, the internal tool selection logic is not fully transparent to end users. We log all tool calls for debugging but do not expose this to users.")_
- **Autonomy & Control:** What level of autonomy does your agent have, and what safeguards are in place? Can the agent take actions that have real-world consequences? How can users override or stop the agent?
  - _(e.g., "Our agent can autonomously send emails through a tool. We implemented a confirmation step for actions that modify external systems. Users can always interrupt the agent's execution.")_
- **Misuse & Safety:** How could your agent be misused? What harmful behaviors could it enable? What safety measures did you implement?
  - _(e.g., "Our agent could be used to generate spam or misinformation. We added content filters and rate limiting. We also restricted the agent from accessing certain APIs that could cause harm.")_
- **Accountability:** Who is responsible when the agent makes an error or causes harm? How do you handle errors and edge cases?
  - _(e.g., "We designed our agent to clearly indicate when it is uncertain and to ask for human confirmation for high-stakes decisions. All agent actions are logged with timestamps for accountability.")_

---

## 8. Conclusion & Future Work

- **Conclusion:** Summarize your project's achievements. Did you meet the objectives you set in Section 2? What are your key takeaways from building an AI agent?
- **Future Work:** If you had another month, what would you add or improve?
  - _(e.g., "We would add more tools," "We would fine-tune a local model," "We would build a proper user interface.")_

---

## 9. References

_(List any external resources you used. This includes academic papers (like Wooldridge), key blog posts, documentation pages, or libraries.)_

- _Wooldridge, M., & Jennings, N. R. (1995). Intelligent agents: Theory and practice. The Knowledge Engineering Review, 10(2), 115â€“152. https://doi.org/10.1017/S0269888900008122 (Or the specific reference from your lecture)_
- _LangChain Documentation. (2024). "Agents." [URL]_
- _LangGraph Documentation. (2024). "Getting Started." [URL]_

---

## 10. Individual Contribution Log

_(**Crucial for your grade.** While Git history is the main source, please summarize your key contributions here. Be specific.)_

### [Student 1 Name]

- _e.g., Set up the initial Git repository and project structure._
- _e.g., Implemented the LangGraph state and conditional logic (Section 3)._
- _e.g., Wrote Section 3 (Architecture) and 4.1 (LLM Selection) of the report._
- _..._

### [Student 2 Name]

- _e.g., Developed and tested the `search_database` and `get_weather` tools (Section 4.2)._
- _e.g., Focused on all prompt engineering and testing (Section 4.3)._
- _e.g., Wrote Section 1 (Exec Summary) and 4.3 (Prompting) of the report._
- _..._

### [Student 3 Name]

- _e.g., Implemented the conversation memory component (Section 4.2)._
- _e.g., Conducted all evaluation and testing, documenting results (Section 5)._
- _e.g., Wrote Section 6 (Theoretical Foundations) and 5 (Evaluation) of the report._
- _..._

### [Student 4 Name]

- _e.g., Researched and integrated the Ollama local model (Section 4.1)._
- _e.g., Debugged the main agent loop and refactored code for clarity._
- _e.g., Wrote Section 2 (Introduction) and 8 (Conclusion) and managed final report editing._
- _..._
